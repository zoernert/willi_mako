# Chatflow-Architektur der Legacy-App

## Ziel und Kontext
Dieses Dokument beschreibt, wie der Chatflow in der Legacy-Anwendung aufgebaut ist ‚Äì von der Benutzerinteraktion √ºber die Retrieval- und Analysephasen bis zur Antwortgenerierung. Es benennt die zentralen Methoden und Funktionen, die Prompting, Thinking, Analyse und Grounding steuern. Das Ziel ist, neue spezialisierte Chat-Flows (Agenten) entwickeln zu k√∂nnen, ohne die bestehende Implementierung zu gef√§hrden.

## High-Level-√úberblick
- **UI & State-Management:** `app-legacy/src/pages/Chat.tsx` ist der prim√§re Einstieg. F√ºr √§ltere Workflows existiert `app-legacy/src/components/ChatFlow.jsx`.
- **Client-Services:** `chatApi.ts`, `OptimizedSearchService.js`, `EnhancedQueryAnalysisService.js`, `ContextExtractionService.js`, `embeddingService.js` orchestrieren Vorverarbeitung und API-Aufrufe.
- **Backend-API:** `/api/chat/chats/:chatId/messages` (implementiert in `src/routes/chat.ts`) koordiniert die gesamte Server-Sequenz inkl. Safeguards, Reasoning und Persistenz.
- **Reasoning-Engine:** `advancedReasoningService.ts` kapselt Thinking-/Analyse-Schritte, `contextManager.ts` und `flip-mode.ts` liefern Grounding- und Pr√§zisierungslogik. Vektor-Suche erfolgt √ºber `QdrantService`.
- **Antwortausgabe:** Responses werden gespeichert, optional um CS/30-Inhalte erweitert (`generateCs30AdditionalResponse`) und mit Timeline/Gamification verkn√ºpft.

## Clientseitiger Ablauf
### 1. UI-Interaktion (`Chat.tsx`)
- `sendMessage` (Zeilen ~520ff) validiert Eingabe, verwaltet Anh√§nge/Screenshots und ruft `chatApi.sendMessage` bzw. `chatApi.sendMessageWithScreenshot` auf.
- Kontext-Flags (`ContextSettings`) steuern Serververhalten z.‚ÄØB. `useDetailedIntentAnalysis`, `includeUserDocuments`, `useWorkspaceOnly`.
- Das UI reagiert auf Antworttypen:
  - `type === 'clarification'` ‚Üí `pendingClarification` Workflow.
  - `hasCs30Additional` ‚Üí Anzeige eines zweiten `assistantMessage` f√ºr CS/30.
- Timeline-Logging via `captureActivity('chat', ‚Ä¶)` sorgt f√ºr Verlaufstracking.

### 2. Redux-basierter Legacy-Flow (`ChatFlow.jsx`)
- `handleSubmit` sendet sofort Benutzer-Nachrichten an den Store (`sendMessage` aus `../actions/chatActions`).
- **Clientseitiges Thinking/Grounding:**
  - `OptimizedSearchService.search(query, options)` kombiniert Query-Expansion, HyDE (`generateHypotheticalAnswer`), Filterung (`EnhancedQueryAnalysisService.createIntelligentFilter`) und Vektor-Suche (`performVectorSearch`).
  - `ContextExtractionService.extractContext(results, collection)` gruppiert Treffer nach Dokumenttyp und baut `rawText` f√ºr den Prompt.
- Anschlie√üend wird `sendChatRequest` ‚Üí POST `/api/chat` ausgef√ºhrt; Response wird via Redux gespeichert.

### 3. Service-Funktionen & reusable Utilities
- `chatApi.ts`
  - `sendMessage(chatId, content, contextSettings?)`
  - `generateResponse` (f√ºr Flip-Mode-Queries)
  - `sendClarification`, `updateShareSettings`, `getPublicChat`
- `OptimizedSearchService`
  - `search`, `performVectorSearch`, `reRankResults`, `fallbackSearch`
- `EnhancedQueryAnalysisService`
  - `optimizeQuery`, `generateHypotheticalAnswer`, `expandQuery`, `createIntelligentFilter`
- `embeddingService`
  - `generateEmbedding`, `generateHypotheticalAnswer`, `expandQueryForSearch`, `fetchCollectionDimension`

## Serversseitiger Ablauf (Route `POST /chat/chats/:chatId/messages`)
1. **Validierung & Deduping**
   - Pr√ºft Eigent√ºmer, nutzt `ensureChatColumns`.
   - Verhindert Doppel-Submits durch Vergleich der letzten Nachricht (Sektion ‚ÄûDeduplicate rapid duplicate submissions‚Äú).
2. **Flip-Mode / Clarification**
   - `flipModeService.analyzeClarificationNeed(content, userId)` erkennt Unklarheiten.
   - Bei Bedarf Speichern eines `clarification`-Message-Objekts und fr√ºhzeitige Response.
3. **Vorbereitung**
   - `previousMessages` & `userPreferences` laden.
   - `contextSettings` aus dem Frontend werden weitergereicht.
4. **Reasoning (Thinking & Analyse)**
   - `advancedReasoningService.generateReasonedResponse(query, history, prefs, contextSettings)` f√ºhrt mehrstufige Pipeline aus:
     - **Quick Retrieval:** `QdrantService.semanticSearchGuided` (Outline-Scoping, Filter) ‚Üí `analyzeContext` bewertet Qualit√§t.
     - **Detailed Intent (optional):** `llm.generateStructuredOutput` f√ºr Intent & Query-Expansion, gesteuert durch `useDetailedIntentAnalysis`.
     - **Enhanced Retrieval:** `generateOptimalSearchQueries`, `performParallelSearch`, LLM-Re-Ranking (`rerankResultsLLM`), Hybrid-Suche.
     - **Response-Erstellung:** `generateDirectResponse` oder `generateRefinedResponse` (iterativ, heuristische Continuation via `llm.generateText`).
     - **Fallbacks:** Timeout ‚Üí `AdvancedRetrieval.getContextualCompressedResults` + `llm.generateResponse`; Fehler ‚Üí vereinfachte Suche.
     - R√ºckgabestruktur enth√§lt `reasoningSteps`, `contextAnalysis`, `qaAnalysis`, `pipelineDecisions`, `apiCallsUsed`.
5. **Grounding mit Benutzerkontext**
   - `contextManager.determineOptimalContext(query, userId, history, contextSettings)` entscheidet, ob Workspace-Dokumente/Notizen genutzt werden.
   - Bei positivem Entscheid: `llm.generateResponseWithUserContext` kombiniert AI-Antwort mit `userContext.userDocuments` & `userNotes`.
6. **Persistenz & Metadaten**
   - Einf√ºgen von User- und Assistant-Messages (Postgres).
   - `responseMetadata` speichert u.‚ÄØa. `reasoningSteps`, `contextSources`, `llmInfo`, Flags zu Hybridsuche & Nutzerkontext.
   - `llm.generateChatTitle` setzt nach erster Antwort den Chat-Titel.
7. **CS/30 Zusatzantwort (optional)**
   - `generateCs30AdditionalResponse` nutzt `qdrantService.searchCs30` und `llm.generateResponse` mit CS/30-Kontext.
   - Ergebnis als zus√§tzliche Nachricht mit `metadata.type = 'cs30_additional'` gespeichert.
8. **Timeline & Gamification**
   - `TimelineActivityService.captureActivity` (dynamisch importiert) protokolliert Chat-Ergebnisse.
   - `GamificationService.awardDocumentUsagePoints` vergibt Punkte bei Nutzung pers√∂nlicher Dokumente.

## Backend-Hilfsdienste und ihre Rollen
| Bereich | Datei/Funktion | Aufgabe |
| --- | --- | --- |
| Retrieval | `QdrantService.semanticSearchGuided`, `QdrantService.searchCs30` | Vektor-Suche, Guided Retrieval, CS/30 Collections |
| Thinking | `advancedReasoningService.generateReasonedResponse`, `generateDirectResponse`, `generateRefinedResponse` | Steuerung der Reasoning-Pipeline, Iteration, Continuation |
| Analyse | `analyzeContext`, `performQAAnalysis`, `computeContextMetrics` (implizit in `buildContextMetrics`) | Qualit√§tseinsch√§tzung der Treffer, Confidence, Topics |
| Grounding | `contextManager.determineOptimalContext`, `workspaceService.searchWorkspaceContent`, `notesService` | Nutzerbezogene Kontexteinbindung |
| Clarification | `flipModeService.analyzeClarificationNeed`, `buildEnhancedQuery` | Abfragepr√§zisierung, Frageb√∂gen, Enhanced Prompts |
| Prompting | `llm.generateResponse`, `llm.generateResponseWithUserContext`, `llm.generateText`, `llm.generateStructuredOutput`, `llm.generateChatTitle` | Kommunikation mit LLM inkl. Varianten (Gemini/Mistral) |
| Fallback | `AdvancedRetrieval.getContextualCompressedResults`, `retrieval.performVectorSearch` | Kompakter Kontext bei Timeouts/Fehlern |

## Erweiterungspunkte f√ºr neue Agenten
1. **Frontend-Konfiguration**
   - Neue Flows k√∂nnen `ContextSettings` erweitern (`overridePipeline`, `workspacePriority` o.‚ÄØ√Ñ.).
   - Zus√§tzliche Buttons/Modi in `Chat.tsx` aktivieren gezielt Features (z.‚ÄØB. ‚ÄûExpert Flow‚Äú ‚Üí `useDetailedIntentAnalysis = true`).
2. **Service-Layer**
   - Spezifische Retrieval-Strategien: eigene Services analog zu `OptimizedSearchService` implementieren und Ergebnisse an `chatApi.sendMessage` h√§ngen.
   - Clientseitige Grounding-Varianten k√∂nnen √ºber `ContextExtractionService` erweitert werden.
3. **Backend-Pipeline**
   - `advancedReasoningService` bietet klare Einstiegspunkte: weitere `ReasoningStep`-Generatoren, z.‚ÄØB. Spezialagenten, k√∂nnen vor/nach `generateReasonedResponse` eingef√ºgt werden.
   - √úber `contextSettings.overridePipeline` (siehe Kommentare im Service) lassen sich alternative Iterationsstrategien aktivieren.
   - Zus√§tzliche Agenten k√∂nnen als eigene Endpunkte im selben Router registriert werden, solange `flipModeService`/`contextManager` wiederverwendet werden.
4. **Sicherheit & Isolation**
   - Neue Flows sollten eigene Feature-Flags nutzen und vorhandene Tabellen (`chats`, `messages`) unver√§ndert lassen.
   - Antwort-Metadaten bieten Raum f√ºr Agent-Kennzeichen (`metadata.agent = 'compliance-audit'`).

## üìå Anforderung: Agent f√ºr Node.js-Tooling (MSCONS ‚Üí InfluxDB)

### Nutzung des bestehenden Chatflows
- **Wissensakquise (Prompting & Grounding):**
  - MSCONS-/EDIFACT-Dokumentation liegt in der `willi_mako`-Collection (Chunk-Typen `pseudocode_*`, `structured_table`, `definition`).
  - Der Agent kann mittels vorhandener Retrieval-Pipeline (`advancedReasoningService` ‚Üí `QdrantService.semanticSearchGuided`) gezielt Fragen zur Struktur stellen; in Antworten sollten Quellen (`metadata.contextSources`, `reasoningSteps`) den Doc-Nachweis liefern.
  - F√ºr fokussierte MSCONS-Abfragen empfiehlt sich ein neues Kontextprofil `contextSettings` mit `overridePipeline` ‚Üí Forced iterative refinement + `useDetailedIntentAnalysis`, damit `generateStructuredOutput` Domain-Entit√§ten extrahiert.
- **Dom√§nenspezifische Extraktion:**
  - Erg√§nzend zur bestehenden Pipeline kann ein optionaler Reasoning-Step eingef√ºgt werden, der MSCONS-Segmente (z.‚ÄØB. `UNH`, `BGM`, `DTM`, `MEA`) identifiziert und als strukturierte JSON-Antwort zur√ºckliefert. Dies l√§sst sich √ºber `advancedReasoningService` um einen weiteren `ReasoningStep` erweitern, bevor die finale Antwort generiert wird.
- **Script-Planung:**
  - Der Agent kann auf Basis der Retrieval-Ergebnisse einen Implementierungsplan erzeugen (Segment-Mapping ‚Üí JSON ‚Üí InfluxDB Line Protocol). Dieser Plan wird weiterhin im Chat pr√§sentiert; Persistenz erfolgt √ºber das bestehende `messages`-System.

### Fehlende/zu erg√§nzende Informationen
- **Sandbox/Code-Ausf√ºhrung:** Aktuell gibt es keinen eingebauten Execution- bzw. Build-Service. F√ºr das Erstellen und Testen von Node.js-Skripten muss eine neue Tool-Schnittstelle geschaffen werden (z.‚ÄØB. Service oder Worker, der npm-Projekte in isolierten Containern ausf√ºhrt). Dieser Schritt ist _nicht_ Teil der vorhandenen Chat-Pipeline und muss separat angebunden werden (neuer `ReasoningStep`, der Toolaufrufe orchestriert).
- **Artefaktverwaltung:** Ergebnisse (z.‚ÄØB. generierte Skripte, `package.json`) werden derzeit nicht automatisch abgelegt. F√ºr NPM-Publishing sind zus√§tzliche Mechanismen n√∂tig (Dateiablage, Zugriff auf Git/Registry-Credentials). In der bestehenden Struktur lie√üe sich das √ºber einen dedizierten Backend-Endpunkt erledigen, der die vom Agenten erzeugten Artefakte entgegennimmt und versioniert.
- **InfluxDB-Verbindungsdetails:** Die Pipeline kennt keine spezifischen Zielsysteme. F√ºr Tests m√ºssen entweder Dummy-Credentials hinterlegt oder ein Mock-Service verwendet werden. Dokumentation dazu sollte, sobald definiert, im Workspace (z.‚ÄØB. `docs/integrations/INFLUX.md`) erg√§nzt und via `ContextExtractionService` referenzierbar sein.

### Vorgehensmodell f√ºr den MSCONS-Agenten
1. **Vorbereitende Abfragen:** Agent nutzt Standard-Chat, um MSCONS-Segmentstruktur, Datentypen, Messwertlogik zu extrahieren (Retrieval + `reasoningSteps` dokumentieren).
2. **Transformationslogik ableiten:** √úber zus√§tzliche Reasoning-Schritte werden Mapping-Tabellen (Segment ‚Üí Influx-Measurement) aufgebaut und als Zwischenergebnis gespeichert (`assistantMessage.metadata.agentPlan`).
3. **Script-Generierung:** Ein neuer Pipeline-Schritt erzeugt das Node.js-Skript (z.‚ÄØB. `mscons-to-influx/index.js`, `package.json`). Ohne Sandbox bleibt dies Text; mit Tool-Schnittstelle kann das Artefakt in einer isolierten Umgebung ausgef√ºhrt und getestet werden.
4. **Validierung & Feedback:** Testergebnisse / Linting werden als weitere Nachrichten (`metadata.agentResult`) zur√ºckgemeldet. Fehlermeldungen flie√üen in die n√§chste Reasoning-Iteration.

Damit l√§sst sich der Agent auf Basis des bestehenden Chatflows konzipieren; die eigentliche Code-Ausf√ºhrung erfordert jedoch eine zus√§tzliche Tooling-Schicht, die noch nicht implementiert ist.

## Empfehlungen f√ºr die Implementierung neuer Flows
- **Keine bestehenden Routen ersetzen**, sondern neue Pfade oder Flags verwenden.
- **ReasoningSteps dokumentieren**: Neue Agenten sollten eigene `step`-Bezeichner setzen, um Debugging im Admin-Interface zu erleichtern.
- **Hybride Kontexte klar kennzeichnen**: Wenn zus√§tzliche Datenquellen genutzt werden, Quellen im `metadata`-Feld des Assistant-Messages ablegen.
- **Timeouts respektieren**: Die Pipeline nutzt ein Budget; neue Agenten sollten entweder ihren eigenen Timeout mitbringen oder den bestehenden `reasoningBudgetMs` ber√ºcksichtigen.
- **Tests**: F√ºr Backend-Erweiterungen `npm run type-check` und relevante Jest-Suites (`jest.integration.config.js`) ausf√ºhren.

## Quick Reference
- **Einstiegspunkt UI:** `Chat.tsx -> sendMessage`
- **API-Client:** `chatApi.sendMessage`
- **Server-Route:** `router.post('/chats/:chatId/messages')`
- **Reasoning Core:** `advancedReasoningService.generateReasonedResponse`
- **Clarification:** `flipModeService.analyzeClarificationNeed`
- **User Context:** `contextManager.determineOptimalContext`
- **CS/30 Zusatz:** `generateCs30AdditionalResponse`

Diese Struktur erlaubt es, spezialisierte Agenten aufzubauen, indem neue Retrieval-/Reasoning-Schritte hinzugef√ºgt, konfigurierbare Flags genutzt oder separate Endpunkte eingef√ºhrt werden ‚Äì ohne den vorhandenen Flow zu destabilisieren.
