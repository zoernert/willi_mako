# API v2 ‚Äì Parallel REST-Architektur Plan

## Ziele
- Eine neue REST-Schicht `api/v2` einf√ºhren, ohne die bestehende Chat-Infrastruktur zu ver√§ndern.
- Schrittweise Entkopplung der Kernfunktionen (Session/Context, Retrieval, Reasoning, Tooling) √ºber klar definierte Endpunkte.
- Parit√§t mit der bestehenden Chat-Erfahrung sicherstellen, bevor Legacy-Code refaktoriert oder abgel√∂st wird.
- Erkenntnisse aus `docs/CHATFLOW.md` als fachlicher Referenzrahmen nutzen, damit API v2 den bestehenden Chatflow exakt widerspiegelt.

## Leitprinzipien
1. **Top-down Iteration:** Zuerst einen neuen Chat-Endpunkt schaffen, der intern den bestehenden Code nutzt (‚ÄûParity Mode‚Äú). Danach Komponentenschnitt folgen lassen.
2. **Session-first:** Benutzerkontext (Session, Workspace, Policies) als eigenes REST-Konzept einf√ºhren, damit sp√§tere Dienste ihn referenzieren k√∂nnen.
3. **Kompatibilit√§t:** Alte Routen bleiben unver√§ndert. Feature-Flags/Config entscheiden, ob neue Clients `api/v2` nutzen.
4. **Dokumentation & Vertr√§ge:** F√ºr jeden neuen Endpunkt OpenAPI-Skizze / JSON-Schema pflegen, um Konsumenten (Agenten, Worker, UIs) zu unterst√ºtzen.
5. **Security & Observability:** AuthN/AuthZ, Rate-Limits und Monitoring mitdenken, auch wenn erste Iteration noch interne Nutzung hat.

## Bezug zum bestehenden Chatflow
Die Legacy-Architektur (siehe `docs/CHATFLOW.md`) liefert die fachliche Vorlage f√ºr API v2. Relevante Zuordnungen:
- **UI/Client-Verhalten:** `Chat.tsx` & `ChatFlow.jsx` ‚Üí `POST /api/v2/chat` muss dieselben States (`type`, `metadata`, CS30-Responses) zur√ºckliefern.
- **Services:**
   - `advancedReasoningService` ‚Üî zuk√ºnftiger `ReasoningService` (`/api/v2/reasoning/generate`).
   - `contextManager` ‚Üî `SessionService` + `ContextService` (`/api/v2/sessions`, `/api/v2/context/resolve`).
   - `QdrantService` ‚Üî Retrieval-Endpunkte.
   - `flip-mode` ‚Üî optionale Clarification-API.
- **Metadaten & Timeline:** Informationen, die heute in `responseMetadata` und Timeline-Events landen, m√ºssen √ºber API v2 transportiert oder emitierbar bleiben.
- **Agenten-Erweiterung:** Die in `CHATFLOW.md` skizzierten Agentenpfade (MSCONS ‚Üí InfluxDB) verwenden k√ºnftig API v2 Endpunkte ‚Äì insbesondere Session, Retrieval, Reasoning und Tooling.

Diese Verkn√ºpfung sorgt daf√ºr, dass API v2 nicht isoliert entsteht, sondern direkt die bestehende Logik reproduziert und erweitert.

## Laufzeitumgebung & Datenquellen
- **Prim√§re Datenbank:** MongoDB (konfiguriert via `MONGO_URI` in `.env`) dient als Schreib-/Lesespeicher f√ºr neue API-v2-Services (Sessions, Artefakte, Tool-Jobs etc.).
- **Postgres (bestehende `DATABASE_URL`):** bleibt read-only f√ºr Legacy-Daten (Chats, Timeline, Gamification). API v2 liest bei Bedarf, f√ºhrt aber keine schreibenden Operationen aus.
- Services m√ºssen explizit kennzeichnen, ob sie Mongo- oder Postgres-Zugriffe ben√∂tigen, damit sp√§tere Migrationen klar bleiben.

### Authentifizierung & Autorisierung
- JWT bleibt das zentrale Authentifizierungsverfahren (Kompatibilit√§t zur Legacy-App).
- Neuer Endpoint `POST /api/v2/auth/token`:
   - Body: `{ email, password }`.
   - Validierung gegen bestehende User-Tabelle / Service.
   - Antwort: `{ accessToken, expiresAt }` mit G√ºltigkeit ‚â• 30 Tage.
   - Signing-Key & Claims kompatibel zum bisherigen Token-Format.
- Alle `api/v2`-Endpoints erwarten `Authorization: Bearer <token>`.
- Langfristig Refresh-/Revoke-Mechanismus pr√ºfen, initial gen√ºgt langer JWT ohne Refresh.

### Rate Limiting (Phase 1 Basis)
- In-Memory Token Bucket / Sliding Window pro `sessionId` + Endpoint.
- Konfiguration via Env (`API_V2_RATE_LIMIT_*`).
- Neustart setzt Limits zur√ºck (keine externe Abh√§ngigkeit).
- Sp√§ter optional Redis/Cluster-Storage, aber erst nach Stabilisierung.

### Metriken & Logging
- Per Endpoint: Requests, Fehlerquote, Latenz (P50/P95), Rate-Limit-Hits.
- Per Session: Anzahl Requests, verwendete Services (retrieval, reasoning, tooling).
- Implementierungsidee: Middleware, die `sessionId` aus Header extrahiert und in Metrics-Namespace schreibt (`api_v2.<endpoint>.<metric>`).
- Export zun√§chst via Prometheus-Endpoint oder strukturierte Logs (JSON) f√ºr sp√§tere Analyse.

## Phasenplan

### Phase 0 ‚Äì Foundations
- Ordnerstruktur `src/presentation/http/api/v2` (Express-Router) + `docs/api/v2/*.md`.
- Gemeinsame DTOs/Interfaces in `src/domain/api-v2` (z.‚ÄØB. `SessionEnvelope`, `ReasoningRequest`).
- Feature-Flag `API_V2_ENABLED` (Env + config service).

### Phase 1 ‚Äì Session & Parity Chat
1. **Session Endpoint**
   - `POST /api/v2/sessions`
     - Input: `userId`, optional `preferences`, `contextSettings` override.
     - Output: `sessionId`, `workspaceContext`, `policyFlags`, TTL/refresh hints.
   - Implementation: Wrap existierenden `contextManager` + User-Profile-Lookups in Service `SessionService`.
2. **Chat Parity Endpoint**
   - `POST /api/v2/chat`
     - Input: `sessionId`, `message`, optionale `contextSettings` (√ºbersteuern Session).
     - Output: Gleiches Schema wie alte Route (`userMessage`, `assistantMessage`, `metadata`).
   - Implementation: interner Aufruf der Legacy-Route (z.‚ÄØB. via `ChatFlowService`), damit Verhalten identisch bleibt.
3. **Auth Token Endpoint**
   - `POST /api/v2/auth/token`
     - Input: `{ email, password }`.
     - Output: `{ accessToken, expiresAt }` (JWT ‚â• 30 Tage g√ºltig).
   - Implementation: nutzt bestehende Auth-Service-Logik; Signing-Key identisch zur Legacy.
4. **Rate Limiting & Metrics Middleware**
   - Globale Middleware f√ºr In-Memory-Limits (`sessionId` + Endpoint) und metric hooks.
   - Logging erweitert um `sessionId`, `endpoint`, `durationMs`, `rateLimited`.
5. **OpenAPI & Test-Client**
   - Automatisch generierte `openapi.json` (Build-Step oder Express-Middleware) nach Phase 1 verf√ºgbar.
   - Minimales Test-Client-Skript oder Insomnia/Postman Collection, um Token holen + Chat-Call gegen `api/v2` zu demonstrieren.
3. **Monitoring**
   - Request-Logging, Metriken (`session_created`, `chat_v2_request_time`).

### Phase 2 ‚Äì Komponenten-Refinement
1. ‚úÖ **Retrieval API** ‚Äì umgesetzt in `POST /api/v2/retrieval/semantic-search`; nutzt den neuen `RetrievalService` als Wrapper um `QdrantService` inklusive Options-Handling und Ergebnis-Metadaten.
2. ‚úÖ **Reasoning API** ‚Äì umgesetzt in `POST /api/v2/reasoning/generate`; kapselt `advancedReasoningService.generateReasonedResponse` √ºber den neuen `ReasoningService` und liefert strukturierte Metadaten.
3. ‚úÖ **Context Resolution** ‚Äì umgesetzt in `POST /api/v2/context/resolve`; verwendet den neuen `ContextService`, der `contextManager.determineOptimalContext` mit Session-Settings kombiniert.
4. ‚úÖ **Clarification / Flip Mode** ‚Äì umgesetzt in `POST /api/v2/clarification/analyze`; stellt die Flip-Analyse inklusive optionaler Enhanced-Query bereit.

### Phase 3 ‚Äì Erweiterte F√§higkeiten
1. ‚úÖ **Tooling / Sandbox (POC)**
   - `POST /api/v2/tools/run-node-script` nimmt Jobs entgegen, validiert Source & Timeout und legt einen gepr√ºften Queue-Eintrag an.
   - `GET /api/v2/tools/jobs/:id` liefert Status, Hash/Preview und Sicherheits-Hinweise; Ausf√ºhrung bleibt manuell (diagnostics `executionEnabled=false`).
   - Persistenz aktuell In-Memory; Nachfolger-Schritt: Worker/Queue f√ºr echte Sandbox-Runner.
2. ‚úÖ **Artefakt-Service (POC)**
   - `POST /api/v2/artifacts` legt Inline-Artefakte (UTF-8/Base64) mit Hash, Preview und Metadaten ab.
   - Unterst√ºtzt optionale Tags, Versionen und sanitisierte Metadata; Speicherung erfolgt vorerst in-memory.
3. **Integration Hooks**
   - Webhooks oder Queue-Events (z.‚ÄØB. `reasoning.completed`) f√ºr Timeline/Gamification.

### Phase 4 ‚Äì Legacy Alignment
- Evaluation: Welche Legacy-Routen k√∂nnen auf API v2 umgestellt werden?
- Refactoring-Plan f√ºr `src/routes/chat.ts` ‚Üí Nutzung von `SessionService`, `ReasoningService` anstelle direkter Aufrufe.
- Cleanup: doppelte Implementierungen entfernen, sobald API v2 stabil ist.

## Endpunkt√ºbersicht (Startversion)
| Endpoint | Zweck | Status |
| --- | --- | --- |
| `POST /api/v2/auth/token` | JWT aus Credentials erzeugen | Phase 1 |
| `POST /api/v2/sessions` | Session/Context anlegen | Phase 1 |
| `POST /api/v2/chat` | Chat-Interaktion mit Parit√§t | Phase 1 |
| `POST /api/v2/retrieval/semantic-search` | Vektor-Suche | Phase 2 |
| `POST /api/v2/reasoning/generate` | LLM-Reasoning | Phase 2 |
| `POST /api/v2/context/resolve` | Workspace-Kontext bestimmen | Phase 2 |
| `POST /api/v2/tools/run-node-script` | Sandbox-Job registrieren (manuelle Freigabe) | Phase 3 (POC) |
| `GET /api/v2/tools/jobs/:id` | Tool-Job Status/Diagnostik abrufen | Phase 3 (POC) |
| `POST /api/v2/artifacts` | Artefakte speichern | Phase 3 (POC) |

## Security Considerations
- **Token-H√§rtung:** Langlebige JWTs werden nur √ºber TLS ausgeliefert; beim Ausbau der Refresh-Mechanik m√ºssen wir Refresh-Token getrennt absichern und Rotations-Logs f√ºhren. Signing-Keys bleiben via Secrets-Manager versioniert.
- **Least Privilege:** Session- und Service-Scopes definieren, sodass Retrieval/Reasoning nur die minimal notwendigen Ressourcen verwenden (z.‚ÄØB. getrennte API-Schl√ºssel f√ºr Qdrant/LLM mit klaren Rollen).
- **Input-Validierung:** Alle `POST /api/v2/*` Endpunkte validieren Payloads strikt (z.‚ÄØB. Zod/JSON-Schema) und rejecten unbekannte Felder, damit kein Injection-Surface entsteht.
- **Datenklassifizierung:** Responses enthalten keine Roh-Personendaten; sensible Felder werden maskiert, Telemetrie erh√§lt nur Hashes (`sessionId`, nicht `userId`).
- **Observability & Audit:** Auth-Fehler, Rate-Limit-Treffer und Admin-Aktionen werden revisionssicher geloggt (PII-safe) und 30 Tage aufbewahrt.
- **Sandbox-Gating:** Tooling-Jobs werden mit Hash/Preview gespeichert, nicht ausgef√ºhrt; zuk√ºnftig nur in isolierten Containern mit erlaubten APIs freigeben.

## Performance Considerations
- **Vektor-Retrieval:** Qdrant-Abfragen nutzen `search_batch` mit Top-K Limit ‚â§ 10, Filter-Indexierung f√ºr h√§ufige Suchen und optionales Cache-Layer (Redis) f√ºr identische Queries pro Session.
- **Reasoning-Latenzen:** LLM-Aufrufe laufen mit Timeout/Abbruchsignal (z.‚ÄØB. 45‚ÄØs) und optionaler Teil-Streaming-Unterst√ºtzung, damit Frontends fr√ºh reagieren k√∂nnen.
- **Session-Kontext:** Context-Resolution cached Workspace-Metadaten pro `sessionId`, invalidiert bei expliziten Overrides und reduziert DB-Hits.
- **Rate Limiting:** Token-Bucket Parameter werden per Env getuned; Reasoning-Endpunkte haben strengere Limits. Drosselung wird fr√ºh (Middleware) durchgef√ºhrt, um CPU-intensive Services zu schonen.
- **Throughput-Scaling:** Backend-Knoten starten mit gepoolten HTTP/DB-Clients; horizontales Scaling erfolgt stateless (Sessions in Mongo), Qdrant erh√§lt separate Auto-Scaling-Policy.
- **Job Queue:** Aktuell In-Memory; Migration auf Redis/Worker vorgesehen, damit Sandbox-Auftr√§ge resilient und parallel ausf√ºhrbar werden.

## Qualit√§tssicherung & Tests
- **Unit-Tests:** Services (Session, Auth, Reasoning-Adapter) erhalten isolierte Tests mit Fixtures f√ºr Mongo/Postgres-Stubs.
- **Integrationstests:** Endpunkt-Tests √ºber Supertest oder Pact, die Feature-Flag-Flow, Auth und Parity-Verhalten gegen Legacy-Route verifizieren.
- **Contract-Tests:** OpenAPI-Schema als Quelle f√ºr Consumer-Tests (z.‚ÄØB. Insomnia CLI, Schemathesis) zur Sicherstellung stabiler Vertr√§ge.
- **Load-/Spike-Checks:** Mindestens synthetische Lasttests f√ºr `POST /chat`, um Rate-Limit-Umschaltung zu verifizieren.
- **CI-Anbindung:** Pipeline-Schritte erg√§nzen (`npm run test:api-v2`, `npm run lint`, OpenAPI-Validation), bevor Merge in `main` m√∂glich ist.

## Datenmodellierung & Migration
- **Collections/Tabellen:** Schema-Definitionen f√ºr Mongo (`sessions`, `artifacts`, `tool_jobs`) in `docs/api/v2/schema/*.json` hinterlegen; Mongoose/Prisma-Models sp√§ter ableiten.
- **Migration Pfad:** Skripte f√ºr initiale Collections anlegen (`npm run db:migrate:api-v2`) und Backfill-Strategie f√ºr Legacy-Sessions beschreiben (nur lesend).
- **Retention & Cleanup:** TTL-Index f√ºr Sessions (z.‚ÄØB. 30 Tage) und Archivierungskonzept f√ºr Artefakte.
- **Cross-DB-Zugriffe:** Klare Adapter-Layer, die Postgres-Reads kapseln, damit Deployment ohne PG optional bleibt (Fallbacks dokumentieren).

## Betrieb & Deployment
- **Feature-Flag-Rollout:** `API_V2_ENABLED` zuerst nur in Staging aktivieren; Canary-Routing f√ºr ausgew√§hlte interne Nutzer.
 - **Konfiguration:** `.env.example` um neue Variablen (`API_V2_RATE_LIMIT_*`, `API_V2_TOKEN_EXPIRES_IN`) erg√§nzen und in README beschreiben.
- **Observability:** Prometheus-Scrape-Pfad (`/metrics/api-v2`) und zentrale Log-Filter (z.‚ÄØB. Loki/ELK) vorbereiten.
- **Incident-Playbook:** R√ºckfall auf Legacy-Routen (Flag toggeln, Sessions invalidieren) muss dokumentiert werden.
- **Security-Review:** Threat-Model durchf√ºhren (Brute Force Token, Session Hijacking) und Checkliste im Projekt-Wiki ablegen.

## Implementierungsstatus (Oktober 2025)
- ‚úÖ Feature-Flag `API_V2_ENABLED` und Router unter `src/presentation/http/routes/api/v2` integriert.
- ‚úÖ Session-Service (`MongoDB` + `chats`-Backlink) inkl. Unit-Test (`tests/unit/api-v2/session.service.test.ts`).
- ‚úÖ Parit√§ts-Chat (`POST /api/v2/chat`) ruft Legacy-Endpunkt mit Rate-Limiter & Metrics auf.
- ‚úÖ Auth-Token Endpoint (`POST /api/v2/auth/token`) mit 30-Tage-JWT.
- ‚úÖ In-Memory Rate-Limiter + Metrics (`/api/v2/metrics`) sowie OpenAPI-Skizze (`/api/v2/openapi.json`).
- ‚úÖ Test-Client (`scripts/api-v2-test-client.ts`) via `npm run test:api-v2`.
- üü° Tooling-Sandbox POC (`POST /api/v2/tools/run-node-script`, `GET /api/v2/tools/jobs/:id`) mit In-Memory Queue, manueller Freigabe und Diagnostik-Hinweisen.
- üü° Artefakt-Service POC (`POST /api/v2/artifacts`) inklusive Hash/Preview, In-Memory-Storage und Validierung.

## Offene Fragen
- Authentifizierung: JWT aus bestehendem System √ºbernehmen oder getrennte Token? Session-Endpunkt muss klar definieren, wie `userId` validiert wird.
- Rate Limiting: Session-Creation und Reasoning begrenzen (z.‚ÄØB. via Redis Token Bucket).
- Observability: Welche Metriken/Logs m√ºssen wir erfassen? Pro Session? Pro Endpoint?
- Versionierung: API v2 Endpunkte sollen stabil bleiben ‚Üí Breaking Changes nur via v3.
- Datenhaltung: Wie werden TTL/Cleanup-Prozesse operationalisiert und wer besitzt sie?
- Compliance: Gibt es Archivierungs-/Audit-Anforderungen, die Mongo-Collections erf√ºllen m√ºssen?

## N√§chste Schritte
1. Sandbox-Runner implementieren (Worker/Queue, isolierte Runtime) und bestehende Jobs migrieren.
2. Webhook-/Queue-Hooks f√ºr Reasoning & Tooling ausarbeiten (Gamification/Timeline).
3. Persistente Speicherung der Tool-Jobs (Mongo/Redis) + Admin-Dashboard zur Freigabe.
4. Artefakt-Speicher persistent machen (z.‚ÄØB. S3/Blob + Mongo-Metadaten) und Retrieval-Endpunkte erg√§nzen.
